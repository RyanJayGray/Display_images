{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Radiolarian classifier.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/RyanJayGray/Display_images/blob/master/Radiolarian_classifier.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "_wZWWgudgIBa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![Effective neural net classification of radiolaria from a sparse dataset](http://paleobots.com/classifier/images/paperimages/smallradiotitle.png)\n",
        "## Abstract\n",
        "A classifier was created using artificial neural nets for the purpose of identifying Radiolaria tests from digitized microscope slide images. The deep neural networks were trained by using images categorized by taxa. Several architectures were evaluated. 1987 total images of sixteen radiolarian species were used to build sparse datasets. Species were specifically chosen to test the ability to automatically identify closely related forms within two genera (6 species within Antarctissa and 7 within Cycladophora), as well as larger differences between these, and two other genera (Helotholus and Lithomelissa). Transmitted light microscope images at different focal planes, without removal of local background (e.g. other microfossils) were used. Through optimization of top-n error rates, a method of dataset preparation and an associated Radiolarian classifier were created and refined. When exposed to new images distinct from those in its training or validation sets, the classifier achieved an average 70% percent top-1 accuracy for the 16 taxa, including discrimination between con-generic forms. A visualization in the form of an interactive dendrogram, using top-5 inference certainties as a measure of morphological distance in a force-directed graph. An application program for mobile devices was created to enable use of the classifier in conjunction with any microscope equipped with a display monitor.\n"
      ]
    },
    {
      "metadata": {
        "id": "f7wLWt8ygkfe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "***Please read and execute this section before continuing***. (This will instantiate the notebook, making all of the code executable, including the live Radiolarian classifier.)\n",
        "\n",
        "The development of the radiolarian classifier proceeded in three phases: curation, training, and classification. Curation involved preparing the image files by normalizing them, organizing them by taxa, and naming them with a rigorous naming scheme. During the training stage hyperparameters were selected, datasets were refined, and a neural net architecture was selected using top-n classification rate as a guiding metric. During the classification stage the neural net was run on a new set of images. The resulting inferences were displayed in order of certainty. Focal plane images were processed as sets. The classifier used these associated images to achieve a higher recognition rate. Resulting inference data was used to render an interactive dendrogram for exploring the relationships between the specimens. The classifier system was also embedded within an app for use on mobile devices.\n",
        "\n",
        "This notebook includes a radiolarian classifier and associated documentation. It classifies radiolarian datasets containing the 16 species for which it has been trained. A method and means of curation and training are also provided to expand upon the classifier's existing capability. Most of the code and tools used in this project are included in this notebook. The primary intent of this notebook is to allow for complete reproducibility of the associated paper's results. This metholodology can also be applied to the creation of other image classifiers from sparse datasets. You are encouraged to make derivative works. If you make use of the code in this notebook, please credit the authors. This notebook was written by Ryan Jay Gray ([Paleobots.com](http://paleobots.com)) with generous support, Radiolarian images, and advice by Drs. David Lazarus and Johan Renaudie of [Museum f√ºr Naturkunde, Berlin](https://https://www.museumfuernaturkunde.berlin/).\n",
        "\n",
        "Place your cursor between the brackets below and press the triangular 'Run cell' icon to load the environment. This will allow execution of the code necessary to curate a dataset, train a neural net, run the classifier and visualize the resulting data with an interactive dendrogram. This setup step may take a minute or more. Once execution of this cell is complete, the Google Colab virtual environment will contain all of the datasets, code, labels and models necessary to reproduce the results in *Effective neural net classification of radiolaria from a sparse dataset*. Keep in mind that the Colaboratory environment is temporary. If you need to keep the results of your classification, save them to your local computer or copy this notebook to your own development environment. If you wish to begin classification of radiolarians independently of this notebook, you may install the [app](#scrollTo=jpORvZtyNOiU).\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "1Eg2_y0u2LB1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# <-- Click inside these brackets to \n",
        "# instantiate this notebook.\n",
        "#\n",
        "# Environment setup code for running this notebook\n",
        "# in Google Colaboratory's virtual environment\n",
        "!mkdir classifier\n",
        "!wget http://paleobots.com/classifier/environment.tar.gz\n",
        "!tar --strip-components 1 -xzf environment.tar.gz\n",
        "!rm environment.tar.gz\n",
        "!apt-get install -y axel imagemagick > /dev/null\n",
        "!echo Environment is instantiated"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JWBriXT825wB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now the notebook is live. You can read this document serially, click on the Table of contents to the left, or use these quick links to major topics:\n",
        "<br><br>\n",
        ">[<img src=\"http://paleobots.com/classifier/images/paperimages/bclassifier.png\">](#scrollTo=8n2fc9qBvXSA)[<img src=\"http://paleobots.com/classifier/images/paperimages/bcuration.png\">](#scrollTo=Vyz709YhgKat)[<img src=\"http://paleobots.com/classifier/images/paperimages/btraining.png\">](#scrollTo=yPjA28eAiDZC)[<img src=\"http://paleobots.com/classifier/images/paperimages/bclassification.png\">](#scrollTo=pA87_oTojoqR)[<img src=\"http://paleobots.com/classifier/images/paperimages/bvisualization.png\">](#scrollTo=FXc_VvDjjrml)[<img src=\"http://paleobots.com/classifier/images/paperimages/bapplication.png\">](#scrollTo=jpORvZtyNOiU)\n",
        "<br><br><br><br><br><br><br>"
      ]
    },
    {
      "metadata": {
        "id": "Vyz709YhgKat",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<br><br>\n",
        "\n",
        "---\n",
        "<br>\n",
        "\n",
        "<p align=\"center\">\n",
        "![alt text](http://paleobots.com/classifier/images/paperimages/bcuration.png)\n",
        "</p>\n",
        "## Curation\n",
        "The original set of images was in multiple file formats, heavily annotated by filename. Care was taken to preserve all of the original information embedded in the file names while accommodating the syntactic requirements of the training and classification code. During training, the neural net acquires class names for taxa from directory names. In order to train the classifier the image files were rigorously sorted into different directories by taxa. Directory names were assigned for accurate classification. Files were uniformly converted to JPEG format. The classifier was written to acquire focal planes from letter designations before the files' extensions (ie: *a.jpg, *b.jpg, etc.). The classifier determines top-n accuracy rates by comparing file names with classes, so abbreviations were expanded and file names were vetted to ensure compliance with the naming system.\n"
      ]
    },
    {
      "metadata": {
        "id": "2-5TF2oqgMZS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Nomenclature"
      ]
    },
    {
      "metadata": {
        "id": "VIU3s-wgS6mi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Initial Radiolaria microphotograph collection summary**\n",
        "\n",
        "This table includes all of the initial species and the core sample they came from. They were initially organized in directories named for samples.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "SMGXo5Z8S6mj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<table cellpadding=\"2\" cellspacing=\"0\">\n",
        "\t<col width=\"152\">\n",
        "\t<col width=\"89\">\n",
        "\t<col width=\"66\">\n",
        "\t<col width=\"81\">\n",
        "\t<col width=\"74\">\n",
        "\t<col width=\"82\">\n",
        "\t<col width=\"68\">\n",
        "\t<col width=\"47\">\n",
        "\t<col width=\"62\">\n",
        "\t<col width=\"84\">\n",
        "\t<col width=\"58\">\n",
        "\t<col width=\"82\">\n",
        "\t<col width=\"85\">\n",
        "\t<col width=\"71\">\n",
        "\t<col width=\"94\">\n",
        "\t<col width=\"65\">\n",
        "\t<col width=\"105\">\n",
        "\t<col width=\"49\">\n",
        "\n",
        "<tr>\n",
        "\t\t<td height=\"17\" style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\"><font size=\"1\">Sample</font></p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\"><font size=\"1\">A denticulata</font></p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\"><font size=\"1\">A ballista</font></p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\"><font size=\"1\">A cylindrica</font></p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\"><font size=\"1\">A strelkovi</font></p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\"><font size=\"1\">A deflandrei</font></p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\"><font size=\"1\">A robusta</font></p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\"><font size=\"1\">L stigi</font></p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\"><font size=\"1\">L setosa</font></p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\"><font size=\"1\">H praevema</font></p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\"><font size=\"1\">H vema</font></p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\"><font size=\"1\">C davisiana</font></p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\"><font size=\"1\">C pliocenica</font></p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\"><font size=\"1\">C bicornis</font></p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\"><font size=\"1\">C cornutoides</font></p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\"><font size=\"1\">C cosma</font></p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\"><font size=\"1\">C spongothorax</font></p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\"><font size=\"1\">C golli</font></p>\n",
        "\t\t</td>\n",
        "\t</tr>\n",
        "\t<tr>\n",
        "\t\t<td height=\"17\" style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\">1138A-2R-4 27/31cm</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"16\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">16</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"19\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">19</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"7\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">7</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"13\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">13</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"7\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">7</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"2\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">2</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t</tr>\n",
        "\t<tr>\n",
        "\t\t<td height=\"17\" style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\">751A-1H-2 7/7cm</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"5\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">5</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"5\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">5</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"1\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">1</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"14\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">14</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"52\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">52</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"5\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">5</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"13\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">13</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t</tr>\n",
        "\t<tr>\n",
        "\t\t<td height=\"17\" style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\">693A-6R-5 48/55cm</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"6\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">6</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"15\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">15</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"4\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">4</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t</tr>\n",
        "\t<tr>\n",
        "\t\t<td height=\"17\" style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\">747A-3H-4 16/24cm</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t</tr>\n",
        "\t<tr>\n",
        "\t\t<td height=\"17\" style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\">751A-3-4 85/87cm</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"1\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">1</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"26\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">26</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"6\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">6</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"30\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">30</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"3\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">3</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t</tr>\n",
        "\t<tr>\n",
        "\t\t<td height=\"17\" style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\">693A-18R-4 101/107cm</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"47\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">47</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"19\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">19</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"29\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">29</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"31\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">31</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"6\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">6</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"7\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">7</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t</tr>\n",
        "\t<tr>\n",
        "\t\t<td height=\"17\" style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\">689B-3H-3 116/118cm</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"4\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">4</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"25\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">25</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"7\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">7</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"10\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">10</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"25\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">25</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"3\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">3</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t</tr>\n",
        "\t<tr>\n",
        "\t\t<td height=\"17\" style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\">1138A-14R-2 50/58cm</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t</tr>\n",
        "\t<tr>\n",
        "\t\t<td height=\"17\" style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\">689B-4H-4 116/118cm</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t</tr>\n",
        "\t<tr>\n",
        "\t\t<td height=\"17\" style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\">1138A-17-2 105/107cm</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"87\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">87</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"3\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">3</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"6\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">6</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"12\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">12</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t</tr>\n",
        "\t<tr>\n",
        "\t\t<td height=\"17\" style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\">278-20-1 77/78cm</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"1\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">1</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"36\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">36</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"8\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">8</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"24\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">24</p>\n",
        "\t\t</td>\n",
        "\t</tr>\n",
        "\t<tr>\n",
        "\t\t<td height=\"17\" style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t</tr>\n",
        "\t<tr>\n",
        "\t\t<td height=\"17\" style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\">Total specimens</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"78\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">78</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"45\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">45</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"82\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">82</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"65\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">65</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"88\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">88</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"36\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">36</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"0\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">0</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"27\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">27</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"31\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">31</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"30\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">30</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"65\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">65</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"13\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">13</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"15\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">15</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"15\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">15</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"14\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">14</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"12\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">12</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"24\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"right\">24</p>\n",
        "\t\t</td>\n",
        "\t</tr>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "id": "ZvB0TwFHS6mk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For each taxa of Radiolaria, a directory was named using proper International Commission on Zoological Nomenclature.\n",
        "\n",
        "Examples: \n",
        "Antarctissa ballista         \n",
        "* Antarctissa cylindrica   \n",
        "* Cycladophora spongothorax \n",
        "* Cycladophora bicornis    \n",
        "* Helotholus praevema\n",
        "\n",
        "This diagram shows the basic structure of a dataset. The root is a folder that names the entire set of images. Names such as dataset022 were used to mark the version of the dataset it contains. The directories within were named after the species they contain. An example is \"Cycladophora bicornis\". This directory holds all of the Cycladophora bicornis image files during training. The directory name defines the class. During classification, this same string is applied to label inferences for all of the image files in the test set. This label is also used to determine the accuracy of results for datasets which conform to the same naming system. e.g., If the inference \"Cycladophora bicornis\" appears in the top-n inferences for the file \"Cycladophora bicornis Axioskop 40X jr-0079 693A-18-4,101.jpg\", the tally of correct identifications is incremented.\n",
        "\n",
        "![Image not loading](http://paleobots.com/classifier/images/paperimages/directory.png \"Directory Structure for datasets\")\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Opw4y8A6S6ml",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The following convention was used to name all of the image files in the datasets. The semantic delimiters are the space and period characters. The values in the first two fields must be spelled correctly because the classifier uses them to provide an accuracy rate for a labeled dataset. The last period in the file name string signifies the last field which is used to process only the image files. The letter character that precedes the period signifies the focal plane. If this character is numeric, then the image is the only focal plane of the specimen.\n"
      ]
    },
    {
      "metadata": {
        "id": "Jk2EnmZSS6ml",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Naming Scheme:\n",
        "\n",
        "<table cellpadding=\"2\" cellspacing=\"0\">\n",
        "\t<col width=\"85\">\n",
        "\t<col width=\"85\">\n",
        "\t<col width=\"85\">\n",
        "\t<col width=\"85\">\n",
        "\t<col width=\"85\">\n",
        "\t<col width=\"85\">\n",
        "\t<col width=\"85\">\n",
        "\t<col width=\"85\">\n",
        "\t<col width=\"85\">\n",
        "\t<col width=\"85\">\n",
        "\t<tr>\n",
        "\t\t<td height=\"17\" style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\">Genus</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\">Species</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\">Sample</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p><br/>\n",
        "\n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\">Microscope</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\">Magnification</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\">Microscopist</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\">Specimen # \n",
        "\t\t\t</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\">Focal Plane</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\">File Format</p>\n",
        "\t\t</td>\n",
        "\t</tr>\n",
        "\t<tr>\n",
        "\t\t<td height=\"17\" style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\">Antarctissa</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\">strelkovi</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\">1138A-2-4</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"27\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"left\">27</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\">Axioskop</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\">40X</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\">jr</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\" sdval=\"-10\" sdnum=\"1033;\">\n",
        "\t\t\t<p align=\"left\">-10</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\">a</p>\n",
        "\t\t</td>\n",
        "\t\t<td style=\"border: none; padding: 0in\">\n",
        "\t\t\t<p align=\"left\">.jpg</p>\n",
        "\t\t</td>\n",
        "\t</tr>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "id": "5bIolnHj5ch0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Image file pre-processing\n",
        "\n",
        "Image files need to be processed to eliminate issues such as file corruption, mismatched codecs, improperly labeled images, and incorrect color spaces. Files were visually examined for corruption, color spaces and mislabeling. Corrupted files were reacquired from original sources. Bad Peggy was used to detect issues with JPEG encoding. The ImageMagick mogrify command was used to convert files to a single colorspace (in the case of these datasets, grayscale encoded into RGB). A codec mismatch was found between some source BMP-format files and the Python image decoder. Mogrify reformatting was used to convert BMP-format files to JPEGs to overcome this and also to significantly reduce the size of the datasets:"
      ]
    },
    {
      "metadata": {
        "id": "4Ys7MF3e_lht",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp \"images/paperimages/A. deflandrei 28 1138A-17-2,105 Olympus BH-2 30X dbl.bmp\" test.bmp\n",
        "!mogrify -format jpg test.bmp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mn4YbPdfgLly",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Normalization of source images and programmatic display of images with units and labels\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "-phzM2xzS6mm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "There were several objective lens-digitizer-microscope combinations used to gather the images. An Axioskop with a 40X objective and AmScope MU300 digitizer and an Olympus BH-2 with 30X objective and AmScope MU300 digitizer. The digitizers recorded images at two resolutions, 1024x768 and 2048x1536. Images were captured in a variety of lighting conditions.\n",
        "\n",
        "To normalize the brightness and contrast of the images\n",
        "\n",
        "To normalize the scale of the images, a calibration slide was photographed. The resulting images were put into the GNU Image Manipulation Program, which was used to find the  resolution of the stage and verify the uniformity of the digitizing . The images were then superimposed to make sure they were about the right size range. The pixels per micrometer were calculated by dividing the amount of pixels measured by the correlating measurement of micrometers. The image directory for the correlating objective were then opened in the terminal and modified with the /mogrify command. This gave the neural net a sense of size for each of the images.\n",
        "\n",
        "The source images were taken on different configurations of microscope/objective lens/digitizer. This causes a problem. The neural net could misclassify an image due to the misrepresented size. In order to correct this, the images have to be normalized. This allowed the radiolaria specimens to be shown with proper units, regardless the size of the source file. This is also important because the images will be cropped to train the neural net only on the specimen images, not the specimen and background debris. To do this, the normalization coefficient of the Axioskop with 40X objective and AmScope MU300 digitizer were found. In order to find this, a calibration slide photographed by the same instrument was compared to an image of a specimen from the instrument. First the calibration slide was superimposed on the to see if the size range was roughly the same. Second, the calibration slide is rotated to fit a horizontal line, and is measured in pixels. The number of pixels for each micrometer is found. \n",
        "\n",
        "There were two types of image files -- those created by the Axioskop 40X objective and AmScope MU300 digitizer, and those created by the Olympus BH-2 with a 30X objective lens digitizer. The images with the 30X objective have image dimensions of 1024x768 or 2048x1536, while the Axioskop optical stack produced images of resolution 2048x1536. A normalization workflow was developed to achieve the same pixels per micrometer throughout the resulting datasets. To preserve information the decision was made to enlarge the smaller files by the appropriate factor. The Olympus files are smaller, so they were processed to match the ppm of the Axioskop images. By dividing the Axioskop normalization coefficient, by the Olympus coefficient, the percentage for resizing was found. This number was then used to resize the Olympus files.\n",
        "\n",
        "To resize images an ImageMagick mogrify command was used. The folders with only Olympus files in them were opened in a terminal. The mogrify command was applied, and the images were normalized.\n",
        "\n",
        "Preforming these calculations also allowed for the Radiolaria specimens to be displayed with proper units, regardless of the size of the source files. This is important because the images were cropped in one family of datasets to train the neural net only on the specimen images, not the specimen and background debris.\n",
        "\n",
        "GNU Image Manipulation Program (GIMP) was used to take initial measurements and then find proper coefficients through successive approximation.\n",
        "\n",
        "All code to perform calculations and programmatic manipulation of images is contained in the Python code sections.\n",
        "\n",
        "\n",
        "Procedure:\n",
        "\n",
        "Normalize sizes of images: \n",
        "\n",
        "  1. Calculate normalization coefficient for Axioskop with 40X objective and AmScope MU300 digitizer\n",
        "   1. select an image from the first set created with an Axioskop with 40X objective and AmScope MU300 digitizer\n",
        "   2. Find dimensions of image in pixels\n",
        "   3. Load corresponding calibration slide(image of calibration slide taken on same 40X objective)\n",
        "   4. Superimpose the two images using GIMP to see if the image is roughly in the size range for Radiolaria \n",
        "   5. Take initial measure of distance and rotation\n",
        "   \n",
        "   ![reticle_grid_Axioskop_40X_rjg.png not found](http://paleobots.com/classifier/images/paperimages/example_astrelkovi_w_reticle_grid_small.jpg \"Axioskop_40X\")\n",
        "   6. Verify calibration image has no skew by reversing rotation and placing horizontal and vertical guides (make sure calibration slide is perpendicular to x-axis)\n",
        "   7. Calculate pixels per micrometer by dividing the amount of pixels measured by the correlating measurement of micrometers\n",
        "   8. Resize the images by opening their file in a terminal and use the /mogrify command, scale the images using the coefficient in step vii\n",
        "  2. Calculate normalization coefficient for Olympus BH-2 with a 30X objective lens and (Need specifications here) digitizer\n",
        "   1. select an image from the first set created with an Axioskop with 30X objective and AmScope MU300 digitizer\n",
        "   2. Find dimensions of image in pixels\n",
        "   3. Find correlating calibration slide(image of calibration slide taken on same 30X objective)\n",
        "   4. Superimpose the two images using GIMP to see if the image is roughly in the size range for Radiolaria \n",
        "   5. Take initial measure of distance and rotation\n",
        "   6. Verify calibration image has no skew by reversing rotation and placing horizontal and vertical guides (make sure calibration slide is perpendicular to x-axis)\n",
        "   7. Calculate pixels per micrometer by dividing the amount of pixels measured by the correlating measurement of micrometers\n",
        "   8. Resize the images by opening their file in a terminal and use the /mogrify command, scale the images using the coefficient in step vii \n",
        "  3. Programmatically load and display images with proper units, grids, titles, and labels\n",
        "\n",
        "**Calibrate image units**\n",
        "\n",
        "* Select an image from the first set created with an Axioskop with 40X objective and AmScope MU300 digitizer:\n",
        "\n",
        "![astrelkovi.jpg](http://paleobots.com/classifier/images/paperimages/astrelkovi.jpg \"A. Strelkovi\")\n",
        "\n",
        "* The dimensions of this image are 2048x1536 pixels\n",
        "\n",
        "* Now, look at the calibration slide for this microscope configuration. (midpoints of minor bars are 10¬µm apart):\n",
        "\n",
        "![scalex40.jpg not loading](http://paleobots.com/classifier/images/paperimages/scalex40.jpg \"Calibration bars\")\n",
        "\n",
        "**Superimpose the two images to see if they are roughly in the size range for Radiolaria**\n",
        "\n",
        "![Image not loading](http://paleobots.com/classifier/images/paperimages/sanity1.jpg \"Simple overlay of calibration bars and specimen photograph\")\n",
        "\n",
        "Check! Individual is ~ 100¬µm\n",
        "\n",
        "* Take initial measure of distance and rotation:\n",
        "\n",
        "![Image not loading](http://paleobots.com/classifier/images/paperimages/anglecorrection.png \"Initial measure\")\n",
        "\n",
        "**Verify calibration image has no skew by reversing rotation and placing horizontal and vertical guides**\n",
        "\n",
        "![Image not loading](http://paleobots.com/classifier/images/paperimages/perpendicularitytest.png \"Corrected for rotation\")\n",
        "\n",
        "Check! Image is orthogonal.\n"
      ]
    },
    {
      "metadata": {
        "id": "GuG6RlMzNQzY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Calculate pixels per micrometer for this configuration of microscope, objective lens, and digitizer**"
      ]
    },
    {
      "metadata": {
        "id": "llDnSbExNM-f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"1781.5/200 = \"+str(1781.5/200))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sbo4V6elNluh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now come up with a coeficient to match 10 pixels per micrometer. This allows for the application of a useful simulated reticle grid to images."
      ]
    },
    {
      "metadata": {
        "id": "i1lJmSisNnV1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(str(10/8.9075))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MwkQW0z5S6mx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Testing this value by scaling the calibration slide image shows that the single measurement has introduced an error of about one percent. Successive approximation produces a more precise value of 1.118164063. In the process a reticle grid was created:\n",
        "\n",
        "![reticle_grid_Axioskop_40X_rjg.png not found](http://paleobots.com/classifier/images/paperimages/example_astrelkovi_w_reticle_grid_small.jpg \"Axioskop_40X\")\n",
        "\n",
        "Images can be displayed, using this coefficient, with proper units for this configuration of microscope, objective lens, and digitizer."
      ]
    },
    {
      "metadata": {
        "id": "EzBe6UcmPRYt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**For the second microscope, an Olympus BH-2 with a 30X objective lens and Amscope MU300 digitizer at 1024x768 resolution:**"
      ]
    },
    {
      "metadata": {
        "id": "QvPZ6NzAS6my",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Calibrate our image units**\n",
        "\n",
        "* Select an image from the second set:\n",
        "\n",
        "![Image not loading](http://paleobots.com/classifier/images/paperimages/A.deflandrei.jpg \"A. deflandrei\")\n",
        "\n",
        "* The dimensions of this image are 1024x768 pixels\n",
        "\n",
        "* Look at the calibration slide for this microscope configuration. (midpoints of minor bars are 10¬µm apart):\n",
        "\n",
        "![Image not loading](http://paleobots.com/classifier/images/paperimages/calibrateLazarus.jpg \"Calibration bars\")\n",
        "\n",
        "**Do a rough comparison**\n",
        "\n",
        "* Superimpose the two images to see if they are roughly in the size range for Radiolaria:\n",
        "\n",
        "![Image not loading](http://paleobots.com/classifier/images/paperimages/sanity2.jpg \"Simple overlay of calibration bars and specimen photograph\")\n",
        "\n",
        "Check! Individual is ~ 85¬µm. This test was conducted in GNU Image Manipulation Program by reducing the alpha of the closer layer.\n",
        "\n",
        "* Take initial measure of distance and rotation:\n",
        "\n",
        "![Image not loading](http://paleobots.com/classifier/images/paperimages/measureminiruler.jpg \"Initial measure\")\n",
        "\n",
        "* Verify calibration image has no skew by reversing rotation and placing horizontal and vertical guides:\n",
        "\n",
        "![Image not loading](http://paleobots.com/classifier/images/paperimages/correctedimage2.png \"Corrected for rotation\")\n",
        "\n",
        "Check! Image is orthogonal."
      ]
    },
    {
      "metadata": {
        "id": "ay_W8ieiS6mz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Calculate pixels per micrometer:"
      ]
    },
    {
      "metadata": {
        "id": "_IfmQZ8oQvmQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"736/250 = \"+str(736/250))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YAz3Mq8jQ5UC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now come up with a coeficient to match 10 pixels per micrometer. This allows for the application of a useful simulated reticle grid to images."
      ]
    },
    {
      "metadata": {
        "id": "bvXkIP2bQ-j_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"\"+str(10/2.944))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ohFXXcFKS6m5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "And verify results. Check!\n",
        "\n",
        "![example_adeflandrei_w_reticle_grid_small.jpg not found](http://paleobots.com/classifier/images/paperimages/example_adeflandrei_w_reticle_grid_small.jpg \"Closeup\")\n",
        "\n",
        "Display images with proper units for this configuration of microscope, objective lens, and digitizer.\n",
        "\n",
        "\n",
        "* First load and plot an image:"
      ]
    },
    {
      "metadata": {
        "id": "8gyEPKbLZ1cl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "image = mpimg.imread('images/paperimages/A. deflandrei 28 1138A-17-2,105 Olympus BH-2 30X dbl.bmp')\n",
        "print(image.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c2xTKiVZVNI6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "image = mpimg.imread('images/paperimages/adeflandrei_cropped.jpg')\n",
        "plt.title(\"A. Deflandrei\\nDimensions:\" + str(image.shape))\n",
        "plt.xlabel('pixels')\n",
        "plt.ylabel('pixels')\n",
        "plt.imshow(image)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "86bP0BxES6m9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Notice that pixels are the units. The approximated ratios can now be applied. \n",
        "\n",
        "Steps:\n",
        "1. Parse original filename for microscope-objective-digitizer configuration.\n",
        "2. Verify resolution match.\n",
        "3. Plot image with proper units.\n",
        "4. Plot image of abritrary size with proper units, title, axis labels, etc.\n",
        "\n",
        "\n",
        "1.&nbsp;Original filename (\"A. deflandrei 28 1138A-17-2,105 Olympus BH-2 30X dbl.bmp\") indicates  Olympus BH-2 with a 30X objective lens. \n",
        "\n",
        "2.&nbsp;Load the image and check resolution:"
      ]
    },
    {
      "metadata": {
        "id": "eYDThb97S6m9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "image = mpimg.imread('images/paperimages/A. deflandrei 28 1138A-17-2,105 Olympus BH-2 30X dbl.bmp')\n",
        "print(image.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SKD23IGjS6m_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "3.&nbsp;Resolution is the expected 1024x768 pixels\n",
        "\n",
        "4.&nbsp;Plot image programmatically with proper units\n",
        "\n",
        "First, plot the larger image with proper units. Also add major and minor gridlines to simulate a reticle."
      ]
    },
    {
      "metadata": {
        "id": "I0OJdpBBS6nA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "import sys  \n",
        "\n",
        "image = mpimg.imread('images/paperimages/A. deflandrei 28 1138A-17-2,105 Olympus BH-2 30X dbl.bmp')\n",
        "olyPPM = 2.944 #Olympus BH-2 30X pixels per micrometer\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig_size = plt.rcParams[\"figure.figsize\"]\n",
        "fig.set_size_inches(fig_size[0]*2, fig_size[1]*2)\n",
        "\n",
        "plt.xlabel('micrometers')\n",
        "plt.ylabel('micrometers')\n",
        "xDim = image.shape[1]/olyPPM\n",
        "yDim = image.shape[0]/olyPPM\n",
        "plt.imshow(image, extent=[0,xDim,0,yDim],alpha=0.7)\n",
        "plt.axis([0,xDim,0,yDim])\n",
        "plt.grid(color='#00FF00',alpha=.2)\n",
        "plt.minorticks_on()\n",
        "plt.grid(b=True, which='minor', color='g', linestyle=':', alpha=0.15)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bbX8AGWlS6nE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "4. Plot image of abritrary size with proper units, title, axis labels, etc.\n",
        "\n",
        "Load an image cropped to display primarily the specimen of interest. This is an image of arbitrary dimensions."
      ]
    },
    {
      "metadata": {
        "id": "Sb7chO32fybY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "image = mpimg.imread('images/paperimages/adeflandrei_cropped.jpg')\n",
        "\n",
        "plt.xlabel('micrometers')\n",
        "plt.ylabel('micrometers')\n",
        "\n",
        "olyPPM = 2.944 #Olympus BH-2 30X pixels per micrometer\n",
        "xDim = image.shape[1]/olyPPM\n",
        "yDim = image.shape[0]/olyPPM\n",
        "plt.imshow(image, extent=[0,xDim,0,yDim], alpha=1)\n",
        "\n",
        "#make this small image easier to see\n",
        "fig = plt.gcf()\n",
        "fig_size = plt.rcParams[\"figure.figsize\"]\n",
        "fig.set_size_inches(fig_size[0]*2, fig_size[1]*2)\n",
        "\n",
        "#make sure ticks display with proper interval\n",
        "plt.xticks(np.arange(0, xDim, 10))\n",
        "plt.grid(color='#00C000',alpha=.2, linestyle='-', linewidth=1)\n",
        "\n",
        "#plt.grid(color='g', linestyle=':', linewidth=.3)\n",
        "plt.minorticks_on()\n",
        "plt.grid(b=True, which='minor', color='g', linewidth=.3, linestyle=':', alpha=0.2)\n",
        "plt.title(\"A. Deflandrei\")\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Aa6Yyv_LS6nJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Dimensions in micrometers are properly calculated and displayed, regardless of cropping."
      ]
    },
    {
      "metadata": {
        "id": "YDmZ6PmBS6nJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Normalize source image files**\n",
        "\n",
        "The images needed to be resized to the appropriate pixels per micrometer. Images were sorted into two directories: those created by the Axioskop 40X objective and AmScope MU300 digitizer, and those created by the Olympus BH-2 with a 30X objective lens and XxY digitizer. The images with the 30X objective are in a resolution of 1024x768 pixels, while the 40X objective have larger dimensions of 2048x1536. To achieve the same pixels per micometer a number of things were done. To preserve information, the files were not made smaller, rather they were be scaled larger. The Olympus files are smaller, so they can be expanded to match the Axioskop files.   \n",
        "\n",
        "Axioskop with 40X objective and AmScope MU300 digitizer = 8.9075 ppm \n",
        "\n",
        "Olympus BH-2 with a 30X objective lens digitizer = 2.944 ppm \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "sqo8GPkcS6nK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Ratio of Axioskop/Olympus PPM:\"+str(8.9075/2.944))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0HqEzaX6JpqK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For images taken on the Olympus BH-2 with 30X objective at the higher resolution of 2048x1536, this coefficient is halved. This also applies to the Olympus BH-2 with the 1024x768 resolution capture combined with a 60X objective:"
      ]
    },
    {
      "metadata": {
        "id": "3I-ftj6HJ5Im",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Ratio of Axioskop/Olympus at 2048x1536 PPM:\"+str(8.9075/2.944/2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5XREikKHS6nN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now that ratio for resizing has been found,the mogrify command can be used on the Olympus images. They have to be resized by percentage, so make sure the resize ratio has been converted into percentage, round to the nearest hundredth. For example:"
      ]
    },
    {
      "metadata": {
        "id": "etZDn8bPtOoK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.image as mpimg\n",
        "\n",
        "!cp \"images/paperimages/A. deflandrei 28 1138A-17-2,105 Olympus BH-2 30X dbl.bmp\" test.bmp\n",
        "image = mpimg.imread('test.bmp')\n",
        "print(image.shape)\n",
        "!mogrify -resize 303% test.bmp\n",
        "image = mpimg.imread('test.bmp')\n",
        "print(image.shape)\n",
        "!mogrify -format jpg test.bmp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dxcbt1Ojp-K9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Image processing\n",
        "\n",
        "Two families of datasets were created: one in which images were used in pre-processed and normalized format, the other in which additional image processing was also performed. The more processed family of datasets were cropped closely about the specimen of interest. The brightness and contrast of the images was randomized about a mean by +- 20%. The final version of each of these datasets are in dataset012 and dataset024. Dataset024 includes the preprocessed and normalized format and dataset012 includes the further processed images.  \n",
        "\n",
        "Both families of datasets were used for training and classification with and without addtional image processing including random flip, rotation, cropping and brigtness manipulations. The additional image processing was not found to significantly affect the recognition rate.\n",
        "\n",
        "Augmentation was used to support the determination to include multiple focal plane images. Particularly sparse image classes were subject to augmentation via image processing. Operations included random crop, flip, rotation, skew and distortion. For this particular set of tests, augmentation produced useful results. More information is provided under the classification section of this notebook. Augmentation was not used in the creation of training and test data for the classifier itself.\n"
      ]
    },
    {
      "metadata": {
        "id": "yPjA28eAiDZC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<br><br>\n",
        "\n",
        "---\n",
        "<br><p align=\"center\">\n",
        "![alt text](http://paleobots.com/classifier/images/paperimages/btraining.png)\n",
        "</p>\n",
        "## Training\n",
        "After curation, the datasets created were used to train the neural net. During this stage the neural net was optimized. Since there was a sparse dataset, transfer learning was employed. Transfer learning is a strategy to increase the recognition rate for small datasets -- neural nets already trained on the Imagenet dataset were used to select features for the layers trained on the Radiolarian images. The neural net architectures that were evaluated were the 16 versions of Mobilenet V1 and Inception V3. The earlier layers of this library of pre-trained neural nets contain features useful for classification of the wide variety of image classes in the larger dataset. Once transfer learning had been implemented, the neural net was optimized. To optimize the neural net, many training tests were conducted, in which datasets were refined and hyperparameters were changed. These hyperparameters included learning rate, number of steps, batch size, and transient distortions that did not affect test sets. The Mobilenet neural net architecture was chosen during this phase on the basis of dedicated tests. The Mobilenet_1.0_224 was eventually selected and is employed in the code in this notebook."
      ]
    },
    {
      "metadata": {
        "id": "khVvPwISiEYr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Procedure for Tests\n",
        "Pre-classified images from the curation stage were sorted into datasets appropriate to each series of test.\n",
        "\n",
        "1. Train the neural net\n",
        "    4. Select a subset of the larger dataset for a test.\n",
        "    6. Select architecture and hyperparameters for neural net, or a range of these in a Jupyter notebook. Once hyperparameters are selected, they will become constant for the remainder of the experiment.\n",
        "    7. Train the neural net (this employs the hardware and software materials listed in the appendices) \n",
        "    8. Use the neural net within the classifier against an unused test set or sets\n",
        "    9. Record the data, and archive the dataset and results on dropbox\n",
        "    10. Iterate from step 1 until sufficient data is acquired to establish constant hyperparameters and a neural net architecture\n",
        "    11. Constants to establish:\n",
        "        13. The selection of taxa\n",
        "        14. Hyperparameters \n",
        "            15. Learning rate\n",
        "            17. Number of steps (of training)\n",
        "            18. Batch size\n",
        "            19. Number of epochs\n",
        "            18. Distortions\n",
        "        19. Neural net architecture\n",
        "2. Classify images\n"
      ]
    },
    {
      "metadata": {
        "id": "Vz-jbW-FiEkX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Evaluation of architectures\n",
        "\n",
        "Different architectures of neural nets suitable for transfer learning were evaluated. The architectures that were used are different variations on Mobilenet, and one version of Inception. Mobilenet is a convolutional neural network. It is a light-weight net that has 30 layers, each layer getting more specific. It operates on two hyperparameters, adjustable for specific datasets: the image resolution, and the width multiplier. The possible multiplier values are 1.0, 0.75, 0.50, and 0.25. The possible image resolutions are 224, 192, 160, and 128. These parameters were varied to produce sixteen potential architectures. Each of these variations was tested, and evaluated by top-1 classification rate. Inception had been demonstrated to achieve a high recognition rate in the ImageNet Large Scale Visual Recognition Challenge in 2015. Inception was evaluated, but with all other variables held constant, Mobilenet delivered a higher recognition rate. Its faster execution allowed for the quick training to find a useful set of hyperparameters. \n",
        "\n",
        "Architectures tested:\n",
        "* Mobilenet_1.0_224\n",
        "* MobileNet_v1_0.50_160\n",
        "* MobileNet_v1_0.25_128\n",
        "* Inception v3\n",
        "\n",
        "#### Procedure\n",
        "1. Select constants from prior tests\n",
        "        1. A set of images for training and testing\n",
        "        2. The selection of taxa\n",
        "        3. Hyperparameters \n",
        "            1. Learning rate\n",
        "            2. Activation function\n",
        "            3. Number of steps(to training)\n",
        "        4. Neural net architecture\n",
        "1. Select architecture\n",
        "2. Train the neural net (this employs the hardware and software materials listed) \n",
        "3. Test the neural net against an unused test set\n",
        "4. Record the results\n",
        "5. Iterate from step two until sufficient data is acquired to select an architecture\n",
        "\n",
        "\n",
        "#### Dataset \n",
        "Description:\n",
        "These images are normalized.\n",
        "\n",
        "The taxa in this dataset are \n",
        "1. Antarctissa Ballista 43 images\n",
        "2. Antarctissa Cylindrica 135 images\n",
        "3. Antarctissa Denticulata 124 images\n",
        "4. Antarctissa Strelkovi 130 images\n",
        "5. Antarctiss Arobusta 35 images\n",
        "6. Cycladophora Golli 45 images \n",
        "7. Helotholus Praevema 50 images\n",
        "8. Antarctissa Deflandrei 91 images\n",
        "9. Cycladophora Bicornis 40 images\n",
        "10. Cycladophora Davisiana 65 images\n",
        "11. Helotholus Vema 58 images\n",
        "12. Lithomelissa Setosa 44 images\n",
        "\n",
        "\n",
        "#### Parameters\n",
        "\n",
        "Architectures: Inception v3 and 16 variations on Mobilenet\n",
        "    * convolution dimension: 3x3\n",
        "    * Activation function: rectified linear unit\n",
        "    * depth: 28 to 30 \n",
        "Preliminary dataset: Imagenet \n",
        "Final layer dataset: archevaldataset.tar.gz\n",
        "Learning rate: default=0.01\n",
        "Number of steps: 400\n",
        "Training percentage: 80%\n",
        "Validation percentage: 10%\n",
        "Testing percentage: 10%\n",
        "\n",
        "python -m scripts.retrain   --bottleneck_dir=tf_files/bottlenecks   --model_dir=tf_files/models/   --summaries_dir=tf_files/training_summaries/\"\"   --output_graph=tf_files/retrained_graph.pb   --output_labels=tf_files/retrained_labels.txt   --architecture=\"mobilenet_1.0_160\" --image_dir=/home/paleo/1radiolaria/archevaldataset --print_misclassified_test_images --how_many_training_steps=400\n",
        "\n",
        "width multiplier: 1.0 0.75 0.50 0.25\n",
        "image resolution: 224, 192, 160, 128\n",
        "\n",
        "\n",
        "#### Results\n",
        "Mobilenet 1.0:\n",
        "* mobilenet_v1_1.0_224: Final test accuracy = 70.9% (N=86)\n",
        "* mobilenet_v1_1.0_192: Final test accuracy = 80.2% (N=86) \n",
        "* MobileNet_v1_1.0_160: Final test accuracy = 75.6% (N=86)\n",
        "* MobileNet_v1_1.0_128: Final test accuracy = 74.4% (N=86)\n",
        "Mobilenet 0.75:\n",
        "* mobilenet_v1_0.75_224: Final test accuracy = 75.6% (N=86)\n",
        "* mobilenet_v1_0.75_192: Final test accuracy = 73.3% (N=86)\n",
        "* mobilenet_v1_0.75_160: Final test accuracy = 75.6% (N=86)\n",
        "* mobilenet_v1_0.75_128: Final test accuracy = 76.7% (N=86)\n",
        "Mobilenet 0.50:\n",
        "* mobilenet_v1_0.50_224: Final test accuracy = 73.3% (N=86)\n",
        "* mobilenet_v1_0.50_192: Final test accuracy = 69.8% (N=86)\n",
        "* mobilenet_v1_0.50_160: Final test accuracy = 74.4% (N=86)\n",
        "* mobilenet_v1_0.50_128: Final test accuracy = 72.1% (N=86) \n",
        "Mobilenet 0.25:\n",
        "* mobilenet_v1_0.25_224: Final test accuracy = 68.6% (N=86) \n",
        "* mobilenet_v1_0.25_192: Final test accuracy = 68.6% (N=86)\n",
        "* mobilenet_v1_0.25_160: Final test accuracy = 61.6% (N=86)\n",
        "* mobilenet_v1_0.25_128: Final test accuracy = 72.1% (N=86)\n",
        "Others:\n",
        "\n",
        "* Inception V3: Final test accuracy = 68.6% (N=86)\n",
        "\n",
        "#### Observations\n",
        "Mobilenet versions provide better results for the datasets than Inception v3 for the chosen parameters. The architecture that provides the best result for this series of tests is mobilenet_v1_1.0_192. Since this architecture provided the best results for a dataset and hyperparameters that had been demonstrated to be most useful in previous tests, it was used for the tests afterward. Subsequent tests and refinements to the workflow led to the selection of the 224x224 image resolution.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "URWfezLjiExO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Optimization metric: top-n accuracy\n",
        "\n",
        "The objective was to create a Radiolarian classifier that delivers human level accuracy. The literature indicates that human level accuracy in the domain of image recognition, is imperfect. Russakovsky, Karpathy et al  observe humans make mistakes and do not always agree on the identification of certain images. Karpathy notes that some images are not of the best quality. They record human level accuracy in a range from 93.6%-97% on images taken from the Imagenet dataset depending on image size. The Imagenet Large Scale Visual Recognition Challenge uses the top-n classification rates. Top-n classification rates are defined as:\n",
        "\n",
        "<img src=\"http://paleobots.com/classifier/images/paperimages/topn.png\" width=\"241\" height=\"152\" hspace=\"200\"/>\n",
        "\n",
        "‚ÄúIn this task, given an image an algorithm will produce 5 class labels ci,i=1,‚Ä¶n in decreasing order of confidence‚Äú (6)\n",
        "\n",
        "The classification rate in this project was optimized using top-1 classification rate. Top-N was used as an indicator of the impact in changes made in the input data, hyperparameters, and variations on architecture. \n"
      ]
    },
    {
      "metadata": {
        "id": "z2WXJ2sjIuYM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Example training run\n",
        "\n",
        "A neural net was trained with a dataset of 16 taxa of Radiolaria."
      ]
    },
    {
      "metadata": {
        "id": "5ybdM4H8YM2d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python \\\n",
        "-m code.train --validation_percentage=12 \\\n",
        "--test_seed=1 \\\n",
        "--bottleneck_dir=tmp/bottlenecks \\\n",
        "--test_set=test_sets/example/ \\\n",
        "--model_dir=tmp/models/ \\\n",
        "--summaries_dir=tmp/training_summaries/ \\\n",
        "--output_graph=models/example.pb   \\\n",
        "--output_labels=labels/example.txt   \\\n",
        "--architecture=\"mobilenet_1.0_224\" \\\n",
        "--image_dir=datasets/dataset202s \\\n",
        "'#--print_misclassified_test_images' \\\n",
        "--how_many_training_steps=500 \\\n",
        "--learning_rate=0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pA87_oTojoqR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<br><br>\n",
        "\n",
        "---\n",
        "<br>\n",
        "<p align=\"center\">\n",
        "![alt text](http://paleobots.com/classifier/images/paperimages/bclassification.png)\n",
        "</p>\n",
        "## Classification\n",
        "\n",
        "After the neural net architecture and hyperparameters were selected, the classifier code was written in Python to perform classification on datasets labeled according to the naming system established in the curation stage. A Monte Carlo cross validation strategy was implemented. An algorithm was selected and implemented for considering focal planes as groups during set selection and classification. Code was written for calculating per-image and per-specimen tallies and accuracies. The classifier read images from a specified dataset and fed them to the specified trained neural net and associated set of class labels. The classifier processed input focal places for each specimen as an associated group. The classifer produced five inferences in order from greatest to least certainty for each image and for each specimen. In determining final inferences and accuracy rates, only the focal plane of greatest certainty for each specimen was considered. The classifier took a top_n argument from 1 to 5 and produced an assessment of its accuracy calculated with this metric based on image labels provided by domain experts.\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Ul5A4rHv8hLC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Example classification run\n",
        "\n",
        "A classification was performed of the radiolarian images that were excluded from the earlier training run. Each filename was displayed by the classifier, followed by the image itself with units, then the top five classifier inferences and their associated certainty. (Only the first ten images are displayed here to conform to Colaboratory‚Äôs output constraint.) Multiple focal planes were included for some specimens. A letter before the ‚Äò.jpg‚Äô extension indicated the focal plane, while the number before the letter indicated the specimen number. At the end of the first run of images, the total count and percentage correctly identified were displayed. In the subsequent accounting, the classifier retained only the focal plane for each image with the inference of greatest certainty. Individual specimens were presented with top five inferences. Finally a total count of specimens and the percentage of them correctly identified by the classifier were displayed."
      ]
    },
    {
      "metadata": {
        "id": "sWlhbF6o8qsn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0, 'code')\n",
        "\n",
        "import classify\n",
        "\n",
        "model_file = \"models/example.pb\"\n",
        "dataset = \"test_sets/example\"\n",
        "label_file = \"labels/example.txt\"\n",
        "\n",
        "classify.evaluateDirectory(model_file,dataset,label_file,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W_nq-KRui1S-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Significance of focal planes\n",
        "\n",
        "The classifier performed uniformly better when given input datasets with multiple focal planes per speciment. Because some sets contained only single plane images per speciment, additional tests were conducted to attempt to quantify the effect of number of focal planes on neural net classification accuracy of fossil Radiolaria, as determined by percentage correctly identified \n",
        "\n",
        "**Independent Variables:**\n",
        "\n",
        "The independent variable for this series of tests was the number of focal planes for a single specimen/individual included in the training set.   \n",
        "Control: Human expert recognition\n",
        "First level: a single plane\n",
        "Second level: 2 focal planes\n",
        "Third Level: 3 focal planes\n",
        "Fourth Level: 4 focal planes\n",
        "\n",
        "**Dependent Variable:**\n",
        "\n",
        "The dependent variable for this series of tests was the recognition accuracy as a percentage of the rate of a human expert.(Which is assumed to be 100% for this experiment.) During testing the neural net was exposed to approximately 114 samples. \n",
        "Dependent Variable Display:\n",
        "The dependent variable was displayed in a scatterplot.\n",
        "\n",
        "**Hypothesis:**\n",
        "\n",
        "If a neural net is trained with the greatest number of planes available for a single specimen for the classification of radiolaria, then it will achieve better results because it can acquire more features associated with a single specimen. The micropaleontologists who captured the images indicated that multiple planes were required for effective recognition by humans. For the application of this experiment, the greatest number of focal planes if four. \n",
        "\n",
        "![Image not loading](http://paleobots.com/classifier/images/paperimages/4focal.png)\n",
        "> *Image series: Four focal planes of Antarctissa deflandrei*\n",
        "\n",
        "![Image not loading](http://paleobots.com/classifier/images/paperimages/focal.jpg)\n",
        "> *Contribution of focal planes to whole image perception*\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "rl-9cIUCXJya",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Procedure**\n",
        "\n",
        "1. Train the neural net\n",
        "    1. Organize the images into directories by taxa\n",
        "    2. Name each directory after the taxon it will be containing\n",
        "    3. Populate each directory with the species\n",
        "        * mogrify  -colorspace Gray \"directory used\"\n",
        "    4. Select architecture and hyperparameters for neural net\n",
        "        * mobilenet_1.0_192 \n",
        "    5. Train the neural net (this employs the hardware and software materials listed) \n",
        "    6. Test the neural net against an unused test set\n",
        "    7. Record the data, and archive the dataset and results\n",
        "    8. Iterate until sufficient data is acquired to establish constants\n",
        "    9. Constants to establish\n",
        "        1. Learning rate\n",
        "        2. Activation function\n",
        "        3. Number of steps(to training)\n",
        "        4. Distortions\n",
        "        5. Neural net architecture\n",
        "        \n",
        "**Dataset** \n",
        "The taxa in this dataset were \n",
        "1. Antarctissa Cylindrica 84 images\n",
        "2. Antarctissa Deflandrei 86 images\n",
        "3. Cycladophora Pliocenica 37 images\n",
        "4. Cycladophora Spongothorax 17 images \n",
        "\n",
        "       \n",
        "**Parameters**       \n",
        "       \n",
        "Architecture: mobilenet_1\n",
        "    * convolution dimension: 3x3\n",
        "    * Activation function: rectified linear unit\n",
        "    * depth: 30 \n",
        "Preliminary dataset: Imagenet \n",
        "Final layer dataset: mobilenet_1.0_192\n",
        "Learning rate: default=0.01\n",
        "Number of steps: 400\n",
        "Training percentage: 80%\n",
        "Validation percentage: 10%\n",
        "Testing percentage: 10%\n",
        "\n",
        "Command line:\n",
        "rm -rf tf_files/bottlenecks\n",
        "python -m scripts.retrain   --bottleneck_dir=tf_files/bottlenecks   --model_dir=tf_files/models/   --summaries_dir=tf_files/training_summaries/\"\"   --output_graph=/home/paleo/Desktop/Science_fair_Radiolaria/Datasets/experiment1_0.pb   --output_labels=tf_files/retrained_labels.txt   --architecture=\"mobilenet_1.0_192\" --image_dir=/home/paleo/Desktop/Science_fair_Radiolaria/Datasets/1FocalPlane --print_misclassified_test_images --how_many_training_steps=400 seed=1,2,3,4,5,6,7,8,9,10,11,12,13,14\n",
        "\n",
        "**Single focal plane**\n",
        "\n",
        "Training and testing was performed with a neural net on a dataset of images with a single focal plane per specimen. \n",
        "\n",
        "**Results:**\n",
        "* no_seed=          Final test accuracy = 87.5%  \n",
        "* testing_seed=1    Final test accuracy = 86.7%\n",
        "* testing_seed=2    Final test accuracy = 95.2%          \n",
        "* testing_seed=3    Final test accuracy = 96.0% \n",
        "* testing_seed=4    Final test accuracy = 88.5% \n",
        "* testing_seed=5    Final test accuracy = 100.0% \n",
        "* testing_seed=6    Final test accuracy = 87.5% \n",
        "* testing_seed=7    Final test accuracy = 95.2%        \n",
        "* testing_seed=8    Final test accuracy = 90.9% \n",
        "* testing_seed=9    Final test accuracy = 90.5%         \n",
        "* testing_seed=10   Final test accuracy = 87.5%           \n",
        "* testing_seed=11   Final test accuracy = 76.5% \n",
        "* testing_seed=12   Final test accuracy = 88.2%           \n",
        "* testing_seed=13   Final test accuracy = 86.4%          \n",
        "* testing_seed=14   Final test accuracy = 91.7%          \n",
        "            \n",
        "* Mean accuracy = 89.88%\n"
      ]
    },
    {
      "metadata": {
        "id": "BRIgv9coYLo5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Two focal planes**\n",
        "\n",
        "Training and testing was performed with a neural net on a dataset of images with two different focal planes per specimen. \n",
        "\n",
        "**Results:** \n",
        "* no_seed=          Final test accuracy = 94.7%\n",
        "* testing_seed=1    Final test accuracy = 96.2%\n",
        "* testing_seed=2    Final test accuracy = 100.0%\n",
        "* testing_seed=3    Final test accuracy = 96.8% \n",
        "* testing_seed=4    Final test accuracy = 94.1% \n",
        "* testing_seed=5    Final test accuracy = 96.0% \n",
        "* testing_seed=6    Final test accuracy = 83.3%\n",
        "* testing_seed=7    Final test accuracy = 97.1%    \n",
        "* testing_seed=8    Final test accuracy = 96.8%\n",
        "* testing_seed=9    Final test accuracy = 95.0%        \n",
        "* testing_seed=10   Final test accuracy = 92.1%          \n",
        "* testing_seed=11   Final test accuracy = 96.8%\n",
        "* testing_seed=12   Final test accuracy = 96.2% \n",
        "* testing_seed=13   Final test accuracy = 91.7%          \n",
        "* testing_seed=14   Final test accuracy = 90.7% \n",
        "\n",
        "* Mean accuracy = 94.5%\n"
      ]
    },
    {
      "metadata": {
        "id": "IG5tQVxMXqR_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Three focal planes**\n",
        "\n",
        "Training and testing was performed with a neural net on a dataset of images with three different focal planes per specimen. \n",
        "\n",
        "**Results:**\n",
        "* no_seed=           Final test accuracy = 100.0%             \n",
        "* testing_seed=1     Final test accuracy = 100.0% \n",
        "* testing_seed=2     Final test accuracy = 100.0%\n",
        "* testing_seed=3     Final test accuracy = 100.0%\n",
        "* testing_seed=4     Final test accuracy = 100.0% \n",
        "* testing_seed=5     Final test accuracy = 100.0%\n",
        "* testing_seed=6     Final test accuracy = 100.0%\n",
        "* testing_seed=7     Final test accuracy = 100.0%\n",
        "* testing_seed=8     Final test accuracy = 93.8%\n",
        "* testing_seed=9     Final test accuracy = 100.0%   \n",
        "* testing_seed=10    Final test accuracy = 100.0%       \n",
        "* testing_seed=11    Final test accuracy = 100.0%\n",
        "* testing_seed=12    Final test accuracy = 92.3%        \n",
        "* testing_seed=13    Final test accuracy = 100.0%        \n",
        "* testing_seed=14    Final test accuracy = 100.0%      \n",
        "            \n",
        "* Mean accuracy = 99.07%\n"
      ]
    },
    {
      "metadata": {
        "id": "kNrG0fmPaP3a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Four focal planes**\n",
        "\n",
        "Training and testing was performed with a neural net on a dataset of images with three different focal planes per specimen. \n",
        "\n",
        "**Results:**\n",
        "* no_seed=            Final test accuracy = 100.0%\n",
        "* testing_seed=1      Final test accuracy = 100.0%\n",
        "* testing_seed=2      Final test accuracy = 100.0%\n",
        "* testing_seed=3      Final test accuracy = 100.0% \n",
        "* testing_seed=4      Final test accuracy = 100.0%\n",
        "* testing_seed=5      Final test accuracy = 100.0%\n",
        "* testing_seed=6      Final test accuracy = 100.0%\n",
        "* testing_seed=7      Final test accuracy = 100.0%\n",
        "* testing_seed=8      Final test accuracy = 100.0%\n",
        "* testing_seed=9      Final test accuracy = 100.0%      \n",
        "* testing_seed=10     Final test accuracy = 100.0%      \n",
        "* testing_seed=11     Final test accuracy = 100.0%\n",
        "* testing_seed=12     Final test accuracy = 100.0%      \n",
        "* testing_seed=13     Final test accuracy = 100.0%        \n",
        "* testing_seed=14     Final test accuracy = 100.0%    \n",
        "            \n",
        "* Mean accuracy = 100%"
      ]
    },
    {
      "metadata": {
        "id": "l9Q1BrkyXLIj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Results and Summary**\n",
        "\n",
        "This experiment was to test the effects of adding additional focal planes of microphotographs of Radiolaria on the recognition rate of a neural net. The purpose of this experiment was to find if more focal planes had an effect on neural net recognition. The initial hypothesis was: If a neural net is trained with the greatest number of planes available for each specimen for the classification of radiolaria, then it will achieve better results because it can acquire more features. The hypothesis is supported by the data collected.\n",
        "The independent variable was the number of focal planes; ranging from one focal plane to four. The dependent variable was the recognition rate as measured in percentage correctly classified. The control group is human recognition, which was 100% for this experiment. \n",
        "2 tables and one graph were created. The first table displays the 15 trials conducted for each level of the IV. The averages calculated were 89.89% for one focal plane, 94.5% for two focal planes, 99.07% for three focal planes, and 100% for four focal planes, which supported the hypothesis. For each level of the IV, the mean recognition rate increased, as seen in table two. Table two displays the average recognition rate and error bars for each level of the IV. Another trend was the standard deviation decreased for each focal plane added. A 6% standard deviation for one plane, 4% for two focal planes, 3% for 3 focal planes, and 0% standard deviation for four focal planes were found.\n",
        " Table three displays the statistics results. A chi-squared test was used to analyze the results. The original expected results were 50% recognition rate for one focal plane, 70% for two focal planes, 80% for 3 focal planes, and 90% for four focal planes as shown in table 3. Unlike a normal test, avaerage recognition rates had to be used due to the number of trials. The final result was a sum of approximately 30.144 chi-squared(x^2). Since there have four IV levels, there have 3 degrees of freedom. So  the third level on the ‚ÄúLevel of Probability table‚Äù was checked. According to this table the results had a less than 0.1% chance of being random. This results in the null hypothesis, all of the recognition rates are the same, being rejected. Therefore the initial hypothesis was supported. \n",
        "![Image not loading](http://paleobots.com/classifier/images/paperimages/scatterplot.png \"Mean Accuracy\")"
      ]
    },
    {
      "metadata": {
        "id": "uFAeHwV8FPGj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Image augmentation**\n",
        "The number of specimens with multiple focal planes was fewer than the number with single focal planes. If the number of images is too small the neural net will not run. Therefore the images required augmentation. Marcus D. Bloice's Augmentor was selected for its simple API and its independence from other graphics libraries. The operations it performed were rotations, reflections, and random small distortions on a training set kept distinct from the final test set.\n",
        "\n",
        "Definition of image augmentation:\n",
        "+ Deep networks need large amount of training data to achieve good performance. To build a powerful image classifier using very little training data, image augmentation is usually required to boost the performance of deep networks. Image augmentationartificially creates training images through different ways of processing or combination of multiple processing, such as random rotation, shifts, shear and flips, etc.(10)\n",
        "\n",
        "**Example augmentation:**"
      ]
    },
    {
      "metadata": {
        "id": "aDCxZ0n89ahA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install Augmentor\n",
        "!wget http://paleobots.com/classifier/datasets_extended.tar.gz\n",
        "!tar -xzf datasets_extended.tar.gz\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eyFdk3-5F1Rf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import Augmentor\n",
        "p = Augmentor.Pipeline(\"datasets_extended/4FocalPlanes/Cycladophora Spongothorax\")\n",
        "\n",
        "p.rotate90(probability=0.5)\n",
        "p.rotate270(probability=0.5)\n",
        "p.flip_left_right(probability=0.8)\n",
        "p.flip_top_bottom(probability=0.3)\n",
        "p.random_distortion(probability=1, grid_width=4, grid_height=4, magnitude=8)\n",
        "\n",
        "p.sample(40)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D3MGIviqi1b5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Procedure for tests of classifier performance on a variety of datasets:**\n",
        "\n",
        "1. Train the neural net\n",
        "    1. Organize the images into directories by taxa\n",
        "    2. Name each directory after the taxon it will be containing\n",
        "    3. Populate each directory with the species\n",
        "    4. Select a subset of the taxa for an experiment\n",
        "    5. Scale: Images were scaled to have a uniform pixels per micrometer. The mogrify command was used on the Olympus images with the appropriate coefficient calculated in Curation. \n",
        "    6. Select architecture and hyperparameters for neural net\n",
        "    7. Train the neural net (this employs the hardware and software materials listed) \n",
        "    8. Test the neural net against an unused test set\n",
        "    9. Record the data, and archive the dataset and results\n",
        "    10. Repeat from 7\n",
        "\n",
        "Datasets\n",
        "Training, validation and test\n",
        "The taxa in this dataset are \n",
        "1. Antarctissa Ballista 43 images\n",
        "2. Antarctissa Cylindrica 135 images\n",
        "3. Antarctissa Denticulata 124 images\n",
        "4. Antarctissa Strelkovi 130 images\n",
        "5. Antarctiss Arobusta 35 images\n",
        "6. Cycladophora Golli 45 images \n",
        "7. Helotholus Praevema 50 images\n",
        "8. Antarctissa Deflandrei 91 images\n",
        "9. Cycladophora Bicornis 40 images\n",
        "10. Cycladophora Davisiana 65 images\n",
        "11. Helotholus Vema 58 images\n",
        "12. Lithomelissa Setosa 44 images\n",
        "\n",
        "Extended test set\n",
        "The taxa in this dataset are \n",
        "1. Antarctissa Ballista\n",
        "2. Antarctissa Cylindrica\n",
        "3. Antarctissa Denticulata\n",
        "4. Antarctissa Strelkovi\n",
        "5. Antarctiss Arobusta\n",
        "6. Cycladophora Golli\n",
        "7. Helotholus Praevema\n",
        "8. Antarctissa Deflandrei\n",
        "9. Cycladophora Bicornis\n",
        "10. Cycladophora Davisiana\n",
        "11. Helotholus Vema\n",
        "12. Lithomelissa Setosa\n",
        "\n",
        "\n",
        "\n",
        "Parameters\n",
        "\n",
        "Architecture: mobilenet_1.0_224\n",
        "    * convolution dimension: 3x3\n",
        "    * Activation function: rectified linear unit\n",
        "    * depth: 30 \n",
        "Preliminary dataset: Imagenet \n",
        "Final layer dataset: dataset_jpgs2size\n",
        "Learning rate: default=0.01\n",
        "Number of steps: 400\n",
        "Training percentage: 80%\n",
        "Validation percentage: 10%\n",
        "Testing percentage: 10%\n",
        "width multiplier: 1.0\n",
        "image resolution: 192\n",
        "\n",
        "python -m scripts.retrain   --bottleneck_dir=tf_files/bottlenecks   --model_dir=tf_files/models/   --summaries_dir=tf_files/training_summaries/\"\"   --output_graph=tf_files/retrained_graph.pb   --output_labels=tf_files/retrained_labels.txt   --architecture=\"mobilenet_1.0_192\" --image_dir=/home/paleo/1radiolaria/dataset_jpgs2size --print_misclassified_test_images --how_many_training_steps=400\n",
        "        \n",
        "        \n"
      ]
    },
    {
      "metadata": {
        "id": "b4Vift3NbRKE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Cross Validation\n",
        "\n",
        "Monte Carlo cross validation, also known as repeated random sub-sampling was employed to assess predictive accuracy and significance of focal planes. An incremented seed was fed to a pseudo-random number generator to select different training, validation and test sets many times. In this example of ten sample classifications, a mean accuracy of specimen classification was found to be 72.63% with .02 standard deviation. A mean accuracy of image classification was found to be 68.88%. In every classification run considering multiple focal planes per specimen, a higher recognition rate was achieved with a mean improvement of 3.75%. In hundreds of informal observations, consideration of multiple focal planes improved recognition rate in all but two instances.  \n",
        "\n",
        "<table cellspacing=\"0\" border=\"0\">\n",
        "\t<colgroup width=\"85\"></colgroup>\n",
        "\t<colgroup width=\"101\"></colgroup>\n",
        "\t<colgroup width=\"95\"></colgroup>\n",
        "\t<colgroup width=\"88\"></colgroup>\n",
        "\t<colgroup span=\"2\" width=\"85\"></colgroup>\n",
        "\t<tr>\n",
        "\t\t<td height=\"17\" align=\"left\"><font face=\"DejaVu Sans\"><br></font></td>\n",
        "\t\t<td align=\"left\"><font face=\"DejaVu Sans\">Accuracy,</font></td>\n",
        "\t\t<td align=\"left\"><font face=\"DejaVu Sans\">Accuracy,</font></td>\n",
        "\t\t<td align=\"left\"><font face=\"DejaVu Sans\"><br></font></td>\n",
        "\t\t<td align=\"left\"><br></td>\n",
        "\t\t<td align=\"left\"><br></td>\n",
        "\t</tr>\n",
        "\t<tr>\n",
        "\t\t<td height=\"17\" align=\"left\"><font face=\"DejaVu Sans\">Seed</font></td>\n",
        "\t\t<td align=\"left\"><font face=\"DejaVu Sans\">per image</font></td>\n",
        "\t\t<td align=\"left\"><font face=\"DejaVu Sans\">per specimen</font></td>\n",
        "\t\t<td align=\"left\"><font face=\"DejaVu Sans\">Improvement</font></td>\n",
        "\t\t<td align=\"right\"><font face=\"DejaVu Sans\">Train time</font></td>\n",
        "\t\t<td align=\"right\"><font face=\"DejaVu Sans\">Classify time</font></td>\n",
        "\t</tr>\n",
        "\t<tr>\n",
        "\t\t<td height=\"17\" align=\"left\" sdval=\"1\" sdnum=\"1033;\"><font face=\"DejaVu Sans\">1</font></td>\n",
        "\t\t<td align=\"left\" sdval=\"0.7191\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">71.91%</font></td>\n",
        "\t\t<td align=\"right\" sdval=\"0.7368\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">73.68%</font></td>\n",
        "\t\t<td align=\"right\" sdval=\"0.0177000000000002\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">1.77%</font></td>\n",
        "\t\t<td align=\"right\" sdnum=\"1033;0;@\"><font face=\"DejaVu Sans\">0:00:34</font></td>\n",
        "\t\t<td align=\"right\" sdnum=\"1033;0;@\"><font face=\"DejaVu Sans\">0:00:53.49</font></td>\n",
        "\t</tr>\n",
        "\t<tr>\n",
        "\t\t<td height=\"17\" align=\"left\" sdval=\"2\" sdnum=\"1033;\"><font face=\"DejaVu Sans\">2</font></td>\n",
        "\t\t<td align=\"left\" sdval=\"0.6742\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">67.42%</font></td>\n",
        "\t\t<td align=\"right\" sdval=\"0.7263\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">72.63%</font></td>\n",
        "\t\t<td align=\"right\" sdval=\"0.0520999999999999\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">5.21%</font></td>\n",
        "\t\t<td align=\"right\" sdnum=\"1033;0;@\"><font face=\"DejaVu Sans\">0:00:34</font></td>\n",
        "\t\t<td align=\"right\" sdnum=\"1033;0;@\"><font face=\"DejaVu Sans\">0:01:07.82</font></td>\n",
        "\t</tr>\n",
        "\t<tr>\n",
        "\t\t<td height=\"17\" align=\"left\" sdval=\"3\" sdnum=\"1033;\"><font face=\"DejaVu Sans\">3</font></td>\n",
        "\t\t<td align=\"left\" sdval=\"0.6685\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">66.85%</font></td>\n",
        "\t\t<td align=\"right\" sdval=\"0.7053\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">70.53%</font></td>\n",
        "\t\t<td align=\"right\" sdval=\"0.0368000000000001\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">3.68%</font></td>\n",
        "\t\t<td align=\"right\" sdnum=\"1033;0;@\"><font face=\"DejaVu Sans\">0:00:34</font></td>\n",
        "\t\t<td align=\"right\" sdnum=\"1033;0;@\"><font face=\"DejaVu Sans\">0:00:55.43</font></td>\n",
        "\t</tr>\n",
        "\t<tr>\n",
        "\t\t<td height=\"17\" align=\"left\" sdval=\"4\" sdnum=\"1033;\"><font face=\"DejaVu Sans\">4</font></td>\n",
        "\t\t<td align=\"left\" sdval=\"0.7022\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">70.22%</font></td>\n",
        "\t\t<td align=\"right\" sdval=\"0.7368\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">73.68%</font></td>\n",
        "\t\t<td align=\"right\" sdval=\"0.0346000000000002\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">3.46%</font></td>\n",
        "\t\t<td align=\"right\" sdnum=\"1033;0;@\"><font face=\"DejaVu Sans\">0:00:34</font></td>\n",
        "\t\t<td align=\"right\" sdnum=\"1033;0;@\"><font face=\"DejaVu Sans\">0:01:24.49</font></td>\n",
        "\t</tr>\n",
        "\t<tr>\n",
        "\t\t<td height=\"17\" align=\"left\" sdval=\"5\" sdnum=\"1033;\"><font face=\"DejaVu Sans\">5</font></td>\n",
        "\t\t<td align=\"left\" sdval=\"0.6742\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">67.42%</font></td>\n",
        "\t\t<td align=\"right\" sdval=\"0.7474\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">74.74%</font></td>\n",
        "\t\t<td align=\"right\" sdval=\"0.0731999999999999\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">7.32%</font></td>\n",
        "\t\t<td align=\"right\" sdnum=\"1033;0;@\"><font face=\"DejaVu Sans\">0:00:34</font></td>\n",
        "\t\t<td align=\"right\" sdnum=\"1033;0;@\"><font face=\"DejaVu Sans\">0:01:39.75</font></td>\n",
        "\t</tr>\n",
        "\t<tr>\n",
        "\t\t<td height=\"17\" align=\"left\" sdval=\"6\" sdnum=\"1033;\"><font face=\"DejaVu Sans\">6</font></td>\n",
        "\t\t<td align=\"left\" sdval=\"0.6854\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">68.54%</font></td>\n",
        "\t\t<td align=\"right\" sdval=\"0.7158\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">71.58%</font></td>\n",
        "\t\t<td align=\"right\" sdval=\"0.0304\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">3.04%</font></td>\n",
        "\t\t<td align=\"right\" sdnum=\"1033;0;@\"><font face=\"DejaVu Sans\">0:00:34</font></td>\n",
        "\t\t<td align=\"right\" sdnum=\"1033;0;@\"><font face=\"DejaVu Sans\">0:01:57.45</font></td>\n",
        "\t</tr>\n",
        "\t<tr>\n",
        "\t\t<td height=\"17\" align=\"left\" sdval=\"7\" sdnum=\"1033;\"><font face=\"DejaVu Sans\">7</font></td>\n",
        "\t\t<td align=\"left\" sdval=\"0.7079\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">70.79%</font></td>\n",
        "\t\t<td align=\"right\" sdval=\"0.7579\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">75.79%</font></td>\n",
        "\t\t<td align=\"right\" sdval=\"0.0499999999999999\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">5.00%</font></td>\n",
        "\t\t<td align=\"right\" sdnum=\"1033;0;@\"><font face=\"DejaVu Sans\">0:00:34</font></td>\n",
        "\t\t<td align=\"right\" sdnum=\"1033;0;@\"><font face=\"DejaVu Sans\">0:02:14.70</font></td>\n",
        "\t</tr>\n",
        "\t<tr>\n",
        "\t\t<td height=\"17\" align=\"left\" sdval=\"8\" sdnum=\"1033;\"><font face=\"DejaVu Sans\">8</font></td>\n",
        "\t\t<td align=\"left\" sdval=\"0.6629\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">66.29%</font></td>\n",
        "\t\t<td align=\"right\" sdval=\"0.7053\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">70.53%</font></td>\n",
        "\t\t<td align=\"right\" sdval=\"0.0424\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">4.24%</font></td>\n",
        "\t\t<td align=\"right\" sdnum=\"1033;0;@\"><font face=\"DejaVu Sans\">0:00:34</font></td>\n",
        "\t\t<td align=\"right\" sdnum=\"1033;0;@\"><font face=\"DejaVu Sans\">0:02:32.39</font></td>\n",
        "\t</tr>\n",
        "\t<tr>\n",
        "\t\t<td height=\"17\" align=\"left\" sdval=\"9\" sdnum=\"1033;\"><font face=\"DejaVu Sans\">9</font></td>\n",
        "\t\t<td align=\"left\" sdval=\"0.7079\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">70.79%</font></td>\n",
        "\t\t<td align=\"right\" sdval=\"0.7368\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">73.68%</font></td>\n",
        "\t\t<td align=\"right\" sdval=\"0.0289\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">2.89%</font></td>\n",
        "\t\t<td align=\"right\" sdnum=\"1033;0;@\"><font face=\"DejaVu Sans\">0:00:34</font></td>\n",
        "\t\t<td align=\"right\" sdnum=\"1033;0;@\"><font face=\"DejaVu Sans\">0:02:52.77</font></td>\n",
        "\t</tr>\n",
        "\t<tr>\n",
        "\t\t<td height=\"17\" align=\"left\" sdval=\"10\" sdnum=\"1033;\"><font face=\"DejaVu Sans\">10</font></td>\n",
        "\t\t<td align=\"left\" sdval=\"0.6854\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">68.54%</font></td>\n",
        "\t\t<td align=\"right\" sdval=\"0.6947\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">69.47%</font></td>\n",
        "\t\t<td align=\"right\" sdval=\"0.00929999999999997\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">0.93%</font></td>\n",
        "\t\t<td align=\"right\" sdnum=\"1033;0;@\"><font face=\"DejaVu Sans\">0:00:34</font></td>\n",
        "\t\t<td align=\"right\" sdnum=\"1033;0;@\"><font face=\"DejaVu Sans\">0:03:12.49</font></td>\n",
        "\t</tr>\n",
        "\t<tr>\n",
        "\t\t<td height=\"17\" align=\"left\"><font face=\"DejaVu Sans\">Mean</font></td>\n",
        "\t\t<td align=\"left\" sdval=\"0.68877\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">68.88%</font></td>\n",
        "\t\t<td align=\"right\" sdval=\"0.72631\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">72.63%</font></td>\n",
        "\t\t<td align=\"right\" sdval=\"0.03754\" sdnum=\"1033;0;0.00%\"><font face=\"DejaVu Sans\">3.75%</font></td>\n",
        "\t\t<td align=\"left\"><br></td>\n",
        "\t\t<td align=\"left\"><br></td>\n",
        "\t</tr>\n",
        "\t<tr>\n",
        "\t\t<td height=\"17\" align=\"left\"><font face=\"DejaVu Sans\">Std Dev.</font></td>\n",
        "\t\t<td align=\"left\" sdval=\"0.0183292143857831\" sdnum=\"1033;0;#,##0.00\"><font face=\"DejaVu Sans\">0.02</font></td>\n",
        "\t\t<td align=\"right\" sdval=\"0.019404455673891\" sdnum=\"1033;0;#,##0.00\"><font face=\"DejaVu Sans\">0.02</font></td>\n",
        "\t\t<td align=\"right\" sdval=\"0.0172871165901083\" sdnum=\"1033;0;#,##0.00\"><font face=\"DejaVu Sans\">0.02</font></td>\n",
        "\t\t<td align=\"left\"><br></td>\n",
        "\t\t<td align=\"left\"><br></td>\n",
        "\t</tr>\n",
        "</table>\n",
        "\n",
        "<br>\n",
        "### Example cross validation run\n",
        "\n",
        "The results in the table above were generated by the example training and classification code below. To execute all of the 10 separate cells sequentially, issue the \"Run all\" or \"Run after\" commands.\n"
      ]
    },
    {
      "metadata": {
        "id": "qb8MM98kcg8C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0, 'code')\n",
        "import classify\n",
        "\n",
        "model_file = \"models/example.pb\"\n",
        "dataset = \"test_sets/example\"\n",
        "label_file = \"labels/example.txt\"\n",
        "\n",
        "!python \\\n",
        "-m code.train --validation_percentage=12 \\\n",
        "--test_seed=1 \\\n",
        "--bottleneck_dir=tmp/bottlenecks \\\n",
        "--test_set=test_sets/example/ \\\n",
        "--model_dir=tmp/models/ \\\n",
        "--summaries_dir=tmp/training_summaries/ \\\n",
        "--output_graph=models/example.pb   \\\n",
        "--output_labels=labels/example.txt   \\\n",
        "--architecture=\"mobilenet_1.0_224\" \\\n",
        "--image_dir=datasets/dataset202s \\\n",
        "--how_many_training_steps=500 \\\n",
        "--learning_rate=0.01\n",
        "\n",
        "classify.evaluateDirectory(model_file,dataset,label_file,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OHwCXFYn7A2V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python \\\n",
        "-m code.train --validation_percentage=12 \\\n",
        "--test_seed=2 \\\n",
        "--bottleneck_dir=tmp/bottlenecks \\\n",
        "--test_set=test_sets/example/ \\\n",
        "--model_dir=tmp/models/ \\\n",
        "--summaries_dir=tmp/training_summaries/ \\\n",
        "--output_graph=models/example.pb   \\\n",
        "--output_labels=labels/example.txt   \\\n",
        "--architecture=\"mobilenet_1.0_224\" \\\n",
        "--image_dir=datasets/dataset202s \\\n",
        "--how_many_training_steps=500 \\\n",
        "--learning_rate=0.01\n",
        "\n",
        "classify.evaluateDirectory(model_file,dataset,label_file,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U4o7kJYU68am",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python \\\n",
        "-m code.train --validation_percentage=12 \\\n",
        "--test_seed=3 \\\n",
        "--bottleneck_dir=tmp/bottlenecks \\\n",
        "--test_set=test_sets/example/ \\\n",
        "--model_dir=tmp/models/ \\\n",
        "--summaries_dir=tmp/training_summaries/ \\\n",
        "--output_graph=models/example.pb   \\\n",
        "--output_labels=labels/example.txt   \\\n",
        "--architecture=\"mobilenet_1.0_224\" \\\n",
        "--image_dir=datasets/dataset202s \\\n",
        "--how_many_training_steps=500 \\\n",
        "--learning_rate=0.01\n",
        "\n",
        "classify.evaluateDirectory(model_file,dataset,label_file,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lo35fKPaL_qc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python \\\n",
        "-m code.train --validation_percentage=12 \\\n",
        "--test_seed=4 \\\n",
        "--bottleneck_dir=tmp/bottlenecks \\\n",
        "--test_set=test_sets/example/ \\\n",
        "--model_dir=tmp/models/ \\\n",
        "--summaries_dir=tmp/training_summaries/ \\\n",
        "--output_graph=models/example.pb   \\\n",
        "--output_labels=labels/example.txt   \\\n",
        "--architecture=\"mobilenet_1.0_224\" \\\n",
        "--image_dir=datasets/dataset202s \\\n",
        "--how_many_training_steps=500 \\\n",
        "--learning_rate=0.01\n",
        "\n",
        "classify.evaluateDirectory(model_file,dataset,label_file,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6nZNgQ397Hmp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python \\\n",
        "-m code.train --validation_percentage=12 \\\n",
        "--test_seed=5 \\\n",
        "--bottleneck_dir=tmp/bottlenecks \\\n",
        "--test_set=test_sets/example/ \\\n",
        "--model_dir=tmp/models/ \\\n",
        "--summaries_dir=tmp/training_summaries/ \\\n",
        "--output_graph=models/example.pb   \\\n",
        "--output_labels=labels/example.txt   \\\n",
        "--architecture=\"mobilenet_1.0_224\" \\\n",
        "--image_dir=datasets/dataset202s \\\n",
        "--how_many_training_steps=500 \\\n",
        "--learning_rate=0.01\n",
        "\n",
        "classify.evaluateDirectory(model_file,dataset,label_file,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "13x0ubM87L9J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python \\\n",
        "-m code.train --validation_percentage=12 \\\n",
        "--test_seed=6 \\\n",
        "--bottleneck_dir=tmp/bottlenecks \\\n",
        "--test_set=test_sets/example/ \\\n",
        "--model_dir=tmp/models/ \\\n",
        "--summaries_dir=tmp/training_summaries/ \\\n",
        "--output_graph=models/example.pb   \\\n",
        "--output_labels=labels/example.txt   \\\n",
        "--architecture=\"mobilenet_1.0_224\" \\\n",
        "--image_dir=datasets/dataset202s \\\n",
        "--how_many_training_steps=500 \\\n",
        "--learning_rate=0.01\n",
        "\n",
        "classify.evaluateDirectory(model_file,dataset,label_file,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LJSPsern7RTb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python \\\n",
        "-m code.train --validation_percentage=12 \\\n",
        "--test_seed=7 \\\n",
        "--bottleneck_dir=tmp/bottlenecks \\\n",
        "--test_set=test_sets/example/ \\\n",
        "--model_dir=tmp/models/ \\\n",
        "--summaries_dir=tmp/training_summaries/ \\\n",
        "--output_graph=models/example.pb   \\\n",
        "--output_labels=labels/example.txt   \\\n",
        "--architecture=\"mobilenet_1.0_224\" \\\n",
        "--image_dir=datasets/dataset202s \\\n",
        "--how_many_training_steps=500 \\\n",
        "--learning_rate=0.01\n",
        "\n",
        "classify.evaluateDirectory(model_file,dataset,label_file,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7qDOoG5FL_dS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python \\\n",
        "-m code.train --validation_percentage=12 \\\n",
        "--test_seed=8 \\\n",
        "--bottleneck_dir=tmp/bottlenecks \\\n",
        "--test_set=test_sets/example/ \\\n",
        "--model_dir=tmp/models/ \\\n",
        "--summaries_dir=tmp/training_summaries/ \\\n",
        "--output_graph=models/example.pb   \\\n",
        "--output_labels=labels/example.txt   \\\n",
        "--architecture=\"mobilenet_1.0_224\" \\\n",
        "--image_dir=datasets/dataset202s \\\n",
        "--how_many_training_steps=500 \\\n",
        "--learning_rate=0.01\n",
        "\n",
        "classify.evaluateDirectory(model_file,dataset,label_file,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DXlR-spy7WJe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python \\\n",
        "-m code.train --validation_percentage=12 \\\n",
        "--test_seed=9 \\\n",
        "--bottleneck_dir=tmp/bottlenecks \\\n",
        "--test_set=test_sets/example/ \\\n",
        "--model_dir=tmp/models/ \\\n",
        "--summaries_dir=tmp/training_summaries/ \\\n",
        "--output_graph=models/example.pb   \\\n",
        "--output_labels=labels/example.txt   \\\n",
        "--architecture=\"mobilenet_1.0_224\" \\\n",
        "--image_dir=datasets/dataset202s \\\n",
        "--how_many_training_steps=500 \\\n",
        "--learning_rate=0.01\n",
        "\n",
        "classify.evaluateDirectory(model_file,dataset,label_file,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vn0P3UlHL-se",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!python \\\n",
        "-m code.train --validation_percentage=12 \\\n",
        "--test_seed=10 \\\n",
        "--bottleneck_dir=tmp/bottlenecks \\\n",
        "--test_set=test_sets/example/ \\\n",
        "--model_dir=tmp/models/ \\\n",
        "--summaries_dir=tmp/training_summaries/ \\\n",
        "--output_graph=models/example.pb   \\\n",
        "--output_labels=labels/example.txt   \\\n",
        "--architecture=\"mobilenet_1.0_224\" \\\n",
        "--image_dir=datasets/dataset202s \\\n",
        "--how_many_training_steps=500 \\\n",
        "--learning_rate=0.01\n",
        "\n",
        "classify.evaluateDirectory(model_file,dataset,label_file,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kU7F7kNF6CEJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Example large dataset classification run\n",
        "\n",
        "A classification was performed of the whole dataset of radiolarian images containing 1,987 image files from 16 different taxa. Each filename was displayed by the classifier, followed by the image itself with units, then the top five classifier inferences and their associated certainty. (Only the first ten images are displayed here to conform to Colaboratory‚Äôs output constraint.) Multiple focal planes were included for some specimens. A letter before the ‚Äò.jpg‚Äô extension indicated the focal plane, while the number before the letter indicated the specimen number. At the end of the first run of images, the total count and percentage correctly identified were displayed. In the subsequent accounting, the classifier retained only the focal plane for each image with the inference of greatest certainty. Individual specimens were presented with top five inferences. Finally a total count of specimens and the percentage of them correctly identified by the classifier were displayed."
      ]
    },
    {
      "metadata": {
        "id": "LNsUbF9OVBss",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0, 'code')\n",
        "\n",
        "import classify\n",
        "\n",
        "model_file = \"models/example.pb\"\n",
        "dataset = \"datasets/dataset100s\"\n",
        "label_file = \"labels/example.txt\"\n",
        "\n",
        "classify.evaluateDirectory(model_file,dataset,label_file,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SQzWvvwliE8Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Analysis/Display of results\n",
        "\n",
        "Results were generally displayed in tabular form. Raw classification results were presented as generated. The file name, labeled by a domain expert was presented at the beginning of each output, followed by the classifier's top five classification inferences and their certainty.The top five inferences were sorted by certainty. At the end of the raw results, a tally of images and top-1 accuracy assessment was shown.\n",
        "\n",
        "Once raw results were presented, the classifier processed results by specimen, considering only the focal plane inference of greatest certainty. A tally of specimens and the respective top-1 accuracy was shown.\n",
        "\n",
        "A force directed graph was also rendered. This graph included representations of organization. The root of the graph was radiolaria, branching out to the genus, and then the separate taxa, and then individual specimens. The forces that directed the nodes were the certainty of inference for each specimen. Individuals were drawn closer to the nodes representing inferences of greater certainty. It is possible this tool could be used for showing morphological distance. If a specimen of a certain species seems closer to another, it could be more closely related to that species. Since fossil radiolaria do not contain DNA, this tool could be useful, because it uses the images of tests of fossil radiolaria to compute morphological distance. "
      ]
    },
    {
      "metadata": {
        "id": "8n2fc9qBvXSA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<br><br>\n",
        "\n",
        "---\n",
        "<br>\n",
        "\n",
        "<p align=\"center\">\n",
        "![Live classifier](http://paleobots.com/classifier/images/paperimages/bclassifier.png)\n",
        "</p>\n",
        "## Live classifier\n",
        "This Radiolarian classifier will identify any Radiolarian images in a dataset that is uploaded in a gzipped file. The classifier's neural net has been trained on a set of images from these taxa:\n",
        "\n",
        "> Antarctissa cylindrica, Cycladophora cosma, Cycladophora spongothorax, Antarctissa deflandrei, Cycladophora davisiana, Helotholus praevema, Antarctissa denticulata, Cycladophora golli, Helotholus vema\n",
        "Antarctissa robusta, Cycladophora humerus, Lithomelissa setosa, Antarctissa strelkovi, Cycladophora pliocenica\n",
        "\n",
        "If the uploaded dataset is labeled according to the system described in the Curation section of this notebook, the classifier will also make a determination of its classification accuracy."
      ]
    },
    {
      "metadata": {
        "id": "mFJ1Lhu8sK_S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# <-- Click inside these brackets to\n",
        "# run the retrained classifier\n",
        "# It will prompt you to upload your gzipped dataset\n",
        "\n",
        "top_n = 5\n",
        "from google.colab import files\n",
        "import tarfile\n",
        "import os\n",
        "import sys\n",
        "\n",
        "sys.path.insert(0, 'code')\n",
        "import classify\n",
        "\n",
        "uploaded = files.upload()\n",
        "fname = list(uploaded.keys())[0]\n",
        "if (fname.endswith(\"tar.gz\")):\n",
        "    tar = tarfile.open(fname, \"r:gz\")\n",
        "    tar.extractall()\n",
        "    tar.close()\n",
        "elif (fname.endswith(\"tar\")):\n",
        "    tar = tarfile.open(fname, \"r:\")\n",
        "    tar.extractall()\n",
        "    tar.close()\n",
        "os.remove(fname)\n",
        "model_file = \"tmp/graph024.pb\"\n",
        "dataset = os.path.splitext(os.path.splitext(fname)[0])[0]\n",
        "label_file = \"tmp/classifier_labels.txt\"\n",
        "\n",
        "classify.evaluateDirectory(model_file,dataset,label_file,top_n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FXc_VvDjjrml",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Visualization\n",
        "\n",
        "Classification results were fed to a force-directed graph using the D3JS library.(7) This interactive graph shows an attractive force between nodes that is proportional to the neural net's certainty in their classification. A repulsive charge distributes the nodes to allow for visualization of relationships. Users of the graph can hover for individual identification and drag nodes to obtain new views."
      ]
    },
    {
      "metadata": {
        "id": "B1o24sg1IpZ5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# <-- Click inside these brackets to create the HTML code\n",
        "# Then click the \"Draw dendrogram\" button to create the live graph\n",
        "import sys\n",
        "sys.path.insert(0, 'code')\n",
        "import dendrogram\n",
        "\n",
        "dendrogram.draw()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jpORvZtyNOiU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Application\n",
        "\n",
        "An android application was written to allow for real-time classification of radiolarians. [The app is available here](https://play.google.com/store/apps/details?id=com.paleobots.radioclassifier).\n",
        "\n",
        "![Image not loading](http://paleobots.com/classifier/images/paperimages/appfar.png)\n",
        "> *The application performing real-time classification of radiolarians from a computer display*\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "![Image not loading](http://paleobots.com/classifier/images/paperimages/appclose.png)\n",
        "> *Close-up of the application at work*"
      ]
    },
    {
      "metadata": {
        "id": "l6NRwSOhMlx3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Appendices"
      ]
    },
    {
      "metadata": {
        "id": "pkF5t9oVjr8U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Bibliography\n",
        "\n",
        "\"A Primer on Python for Life Science Researchers - PLOS.\" 30 Nov. 2007, http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.0030199.\n",
        "\n",
        "\"Life History and Ecology of the Radiolaria.\" http://www.ucmp.berkeley.edu/protista/radiolaria/radlh.html.\n",
        "\n",
        "\"Late Pleistocene-Holocene radiolarian ... - ePIC - AWI.\" http://epic.awi.de/10506/.\n",
        "\n",
        "\"RadSS: A radiolarian classifier using support vector ... - IEEE Xplore.\" 19 Dec. 2016, http://ieeexplore.ieee.org/document/7785347/.\n",
        "\n",
        "Ke√ßeli, Ali Seydi & Kaya, Aydin & Uzun√ßimen Ke√ßeli, Seda. (2017). Classification of radiolarian images with hand-crafted and deep features. Computers & Geosciences. 109. . 10.1016/j.cageo.2017.08.011. https://www.researchgate.net/publication/319158131_Classification_of_radiolarian_images_with_hand-crafted_and_deep_features\n",
        "\n",
        "\"[1409.0575] ImageNet Large Scale Visual Recognition Challenge - arXiv.\" 1 Sep. 2014, https://arxiv.org/abs/1409.0575.\n",
        "\n",
        "\"A Hybrid Space-Filling and Force-Directed Layout Method for ....\" http://vis.cs.ucdavis.edu/papers/pacificvis09_Itoh.pdf. Accessed 2 Jan. 2018.\n",
        "\n",
        "\"MobileNets: Efficient Convolutional Neural Networks for Mobile Vision ....\" 17 Apr. 2017, https://arxiv.org/abs/1704.04861. Accessed 8 Apr. 2018.\"\n",
        "\n",
        "(9) \"Image Augmentation for Deep Learning ‚Äì Towards Data Science.\" 10 Jul. 2017, https://towardsdatascience.com/image-augmentation-for-deep-learning-histogram-equalization-a71387f609b2. Accessed 8 Jan. 2018."
      ]
    },
    {
      "metadata": {
        "id": "Ea-Mm6Vujrti",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training code"
      ]
    },
    {
      "metadata": {
        "id": "Kgdg85GfoKut",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cat code/train.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LHO5LfTLjr06",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Classification code"
      ]
    },
    {
      "metadata": {
        "id": "kITYvavpoWqO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cat code/classify.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qC8gqi7z2_DH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Visualization code"
      ]
    },
    {
      "metadata": {
        "id": "AwZWH3zk2_DJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cat code/dendrogram.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2xHv3bMU4CKP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Selection of tools based on objectives\n",
        "\n",
        "The objective of the research was to create a radiolarian classifier that reaches a reproducible human-level recognition rate. This guided the selection of tools. The decision was made to use open-source materials, and to perform the task with tools that use inexpensive, commonly-available CPUs, and GPUs. For documentation, Jupyter notebooks is an open-source interactive environment that can execute code, and has the abilities of HTML, supporting easy access and reproducibility for other researchers. Python is a widely used programming language for analytical data sciences. It is open source. It supports a wide variety of tools and is used as the foundation for programs such as Jupyter notebooks. Machine learning environments using Python on the open source GNU/Linux OS include Caffe, Theano and TensorFlow. For transfer learning the ImageNet database provides a large image dataset with labels. Google provides open-sourced pretrained models based on this database which already contained image recognition features."
      ]
    },
    {
      "metadata": {
        "id": "jm3Y9ZTlT1od",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Equipment and Materials:\n",
        "Computer, Model: Linux Os AMD FX-6100 cpu NVidia 1060 GT GPU\n",
        "1150 Radiolarian images of 17 taxa in BMP and JPEG format, Resolutions, 1024x768 and 2048x1536, 24 bit RGB: Species: A denticulata, A ballista, A cylindrica, A strelkovi, A deflandrei, A robusta, L setosa, H praevema, H vema, C davisiana, C pliocenica, C bicornis, C cornutoides, C cosma, C spongothorax, C golli\n",
        "Free and open-source software development environment: Linux, Python 3.6, Anaconda, Spyder, Jupyter Notebooks, Numpy, Mobilenet, MatplotLib, GNU Image Manipulation Program, Libre Office\n",
        "Proprietary software: NVidia CUDA, cuDNN, Dropbox"
      ]
    }
  ]
}